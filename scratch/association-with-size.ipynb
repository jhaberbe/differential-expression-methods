{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c0a042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaberbe/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import patsy\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"/home/jhaberbe/Projects/using_parameters_instead/data/16APR2025.h5ad\")\n",
    "adata.obs.query(\"folder == '05-27' and cell_type == 'Microglia-PVM'\")\n",
    "adata.obs[\"log_lipid_droplet_area\"] = np.log1p(adata.obs[\"lipid_droplet_area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5282edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = patsy.dmatrix(\"log_lipid_droplet_area + near_amyloid\", adata.obs, return_type=\"dataframe\")\n",
    "exog = torch.tensor(exog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5018148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2452/3510302487.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  size_factor = torch.tensor(np.log(adata.layers[\"transcript\"].sum(axis=1) / adata.layers[\"transcript\"].sum(axis=1).mean()))\n"
     ]
    }
   ],
   "source": [
    "intercept = exog[:, 0].float()\n",
    "log_lipid_droplet_area = exog[:, 1].float()\n",
    "amyloid = exog[:, 2].float()\n",
    "counts = torch.tensor(adata[:, \"APOE\"].layers[\"transcript\"].reshape(-1)).float()\n",
    "all_counts = torch.tensor(adata.layers[\"transcript\"]).float()\n",
    "size_factor = torch.tensor(np.log(adata.layers[\"transcript\"].sum(axis=1) / adata.layers[\"transcript\"].sum(axis=1).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d1884",
   "metadata": {},
   "source": [
    "# Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "34cdfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "from torch.distributions import constraints\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "from torch.distributions import constraints\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def model(amyloid, log_lipid_droplet_area, size_factor, counts):\n",
    "    device = log_lipid_droplet_area.device\n",
    "\n",
    "    # Intercept\n",
    "    intercept = pyro.sample(\"intercept\", dist.Normal(\n",
    "        torch.tensor(0.0, device=device), torch.tensor(5.0, device=device)))\n",
    "\n",
    "    # Near Amyloid effect\n",
    "    amyloid_loc = pyro.param(\"amyloid\", torch.tensor(1.0, device=device))\n",
    "\n",
    "    # Sparse GP\n",
    "    kernel = gp.kernels.RBF(\n",
    "        input_dim=1,\n",
    "        variance=log_lipid_droplet_area.var(),\n",
    "        lengthscale=torch.tensor(.1, device=device)\n",
    "    )\n",
    "    Xu = torch.linspace(0, 7, 10, device=device).unsqueeze(-1)  # (10, 1)\n",
    "    gpr = gp.models.VariationalSparseGP(\n",
    "        log_lipid_droplet_area, Xu=Xu, y=None, kernel=kernel, likelihood=None\n",
    "    )\n",
    "\n",
    "    ld_loc, ld_scale = gpr(log_lipid_droplet_area)\n",
    "    with pyro.plate(\"data\", log_lipid_droplet_area.shape[0]):\n",
    "        ld_sampled = pyro.sample(\"ld_sampled\", dist.Normal(ld_loc, ld_scale))\n",
    "\n",
    "    # Logit calculation\n",
    "    logit = intercept + (amyloid * amyloid_loc) + (log_lipid_droplet_area * ld_sampled) + size_factor\n",
    "    logit = 20 * torch.tanh(logit / 20)\n",
    "\n",
    "    # Dispersion\n",
    "    r = pyro.param(\"r\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
    "\n",
    "    with pyro.plate(\"observations\", len(counts)):\n",
    "        pyro.sample(\"counts\", dist.NegativeBinomial(total_count=r, logits=logit), obs=counts)\n",
    "\n",
    "\n",
    "def guide(amyloid, log_lipid_droplet_area, size_factor, counts):\n",
    "    device = log_lipid_droplet_area.device\n",
    "\n",
    "    # Intercept\n",
    "    intercept_loc = pyro.param(\"intercept_loc\", torch.tensor(0.0, device=device))\n",
    "    intercept_scale = pyro.param(\"intercept_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"intercept\", dist.Normal(intercept_loc, intercept_scale))\n",
    "\n",
    "    # Amyloid\n",
    "    amyloid_loc = pyro.param(\"amyloid_loc\", torch.tensor(0.0, device=device))\n",
    "    amyloid_scale = pyro.param(\"amyloid_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"amyloid\", dist.Normal(amyloid_loc, amyloid_scale))\n",
    "\n",
    "    # Sparse GP (for consistency, same kernel setup)\n",
    "    kernel = gp.kernels.RBF(\n",
    "        input_dim=1,\n",
    "        variance=log_lipid_droplet_area.var(),\n",
    "        lengthscale=torch.tensor(0.05, device=device)\n",
    "    )\n",
    "    Xu = torch.linspace(0, 7, 10, device=device).unsqueeze(-1)\n",
    "    gpr = gp.models.VariationalSparseGP(\n",
    "        log_lipid_droplet_area, Xu=Xu, y=None, kernel=kernel, likelihood=None\n",
    "    )\n",
    "    gpr.guide()\n",
    "\n",
    "    # Dispersion\n",
    "    r_loc = pyro.param(\"r_loc\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
    "    r_scale = pyro.param(\"r_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"r\", dist.LogNormal(r_loc, r_scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aac556bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaberbe/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/util.py:288: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n",
      "{'amyloid', 'u', 'r'}\n",
      "  warnings.warn(\n",
      "/home/jhaberbe/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/util.py:303: UserWarning: Found vars in model but not guide: {'ld_sampled'}\n",
      "  warnings.warn(f\"Found vars in model but not guide: {bad_sites}\")\n",
      "/tmp/ipykernel_2452/2175784865.py:53: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  intercept_loc = pyro.param(\"intercept_loc\", torch.tensor(0.0, device=device))\n",
      "/tmp/ipykernel_2452/2175784865.py:54: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  intercept_scale = pyro.param(\"intercept_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
      "/tmp/ipykernel_2452/2175784865.py:58: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  amyloid_loc = pyro.param(\"amyloid_loc\", torch.tensor(0.0, device=device))\n",
      "/tmp/ipykernel_2452/2175784865.py:59: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  amyloid_scale = pyro.param(\"amyloid_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
      "/tmp/ipykernel_2452/2175784865.py:66: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lengthscale=torch.tensor(0.05, device=device)\n",
      "/home/jhaberbe/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/distributions/util.py:340: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  eye.view(-1)[: min(m, n) * n : n + 1] = 1\n",
      "/tmp/ipykernel_2452/2175784865.py:75: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  r_loc = pyro.param(\"r_loc\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
      "/tmp/ipykernel_2452/2175784865.py:76: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  r_scale = pyro.param(\"r_scale\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
      "/tmp/ipykernel_2452/2175784865.py:18: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(0.0, device=device), torch.tensor(5.0, device=device)))\n",
      "/tmp/ipykernel_2452/2175784865.py:21: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  amyloid_loc = pyro.param(\"amyloid\", torch.tensor(1.0, device=device))\n",
      "/tmp/ipykernel_2452/2175784865.py:27: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lengthscale=torch.tensor(.1, device=device)\n",
      "/home/jhaberbe/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/contrib/gp/kernels/isotropic.py:49: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if X.size(1) != Z.size(1):\n",
      "/tmp/ipykernel_2452/2175784865.py:43: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  r = pyro.param(\"r\", torch.tensor(1.0, device=device), constraint=constraints.positive)\n",
      "/tmp/ipykernel_2452/2175784865.py:45: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  with pyro.plate(\"observations\", len(counts)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 3478736.6501526376\n",
      "Step 2: Loss = 3341995.3751685717\n",
      "Step 4: Loss = 3177742.6264904006\n",
      "Step 6: Loss = 3125752.372673844\n",
      "Step 8: Loss = 3075860.1234712563\n",
      "Step 10: Loss = 3024977.0566820204\n",
      "Step 12: Loss = 3002045.6886047595\n",
      "Step 14: Loss = 2874864.2679418996\n",
      "Step 16: Loss = 3025971.294016575\n",
      "Step 18: Loss = 2852453.760690337\n",
      "Step 20: Loss = 2707901.586193286\n",
      "Step 22: Loss = 2704472.8686299473\n",
      "Step 24: Loss = 2595439.1647904045\n",
      "Step 26: Loss = 2578527.26710815\n",
      "Step 28: Loss = 2535223.0239046705\n",
      "Step 30: Loss = 2469773.6904095765\n",
      "Step 32: Loss = 2471122.431046986\n",
      "Step 34: Loss = 2385397.2027744185\n",
      "Step 36: Loss = 2361206.8523398163\n",
      "Step 38: Loss = 2240716.7416331423\n",
      "Step 40: Loss = 2445570.558201366\n",
      "Step 42: Loss = 2162063.2421009745\n",
      "Step 44: Loss = 2196585.639430426\n",
      "Step 46: Loss = 2117160.076130147\n",
      "Step 48: Loss = 2196425.103969982\n",
      "Step 50: Loss = 1989566.6950190696\n",
      "Step 52: Loss = 2318719.0472960128\n",
      "Step 54: Loss = 1883485.0870610012\n",
      "Step 56: Loss = 1880533.645572285\n",
      "Step 58: Loss = 1995769.5114443433\n",
      "Step 60: Loss = 1795340.5655436465\n",
      "Step 62: Loss = 2073243.3643270459\n",
      "Step 64: Loss = 1720778.6538318265\n",
      "Step 66: Loss = 1701322.515544512\n",
      "Step 68: Loss = 1878695.8702700578\n",
      "Step 70: Loss = 1556185.9130850118\n",
      "Step 72: Loss = 1597842.5702910796\n",
      "Step 74: Loss = 1499410.4486755724\n",
      "Step 76: Loss = 1469953.93761425\n",
      "Step 78: Loss = 1491867.6510907176\n",
      "Step 80: Loss = 1361016.7472285554\n",
      "Step 82: Loss = 1338156.9947611806\n",
      "Step 84: Loss = 1404561.6121577825\n",
      "Step 86: Loss = 1263858.020398456\n",
      "Step 88: Loss = 1234441.2870715843\n",
      "Step 90: Loss = 1159824.7976645706\n",
      "Step 92: Loss = 1165480.6590416515\n",
      "Step 94: Loss = 1099098.6362664537\n",
      "Step 96: Loss = 1326072.7962020303\n",
      "Step 98: Loss = 1023646.6142780602\n",
      "Step 100: Loss = 965901.7698554188\n",
      "Step 102: Loss = 974492.3225741545\n",
      "Step 104: Loss = 911113.7678868641\n",
      "Step 106: Loss = 859847.2809914853\n",
      "Step 108: Loss = 840946.5693785818\n",
      "Step 110: Loss = 815311.2479705162\n",
      "Step 112: Loss = 737100.128324796\n",
      "Step 114: Loss = 881339.4329159444\n",
      "Step 116: Loss = 685876.356492929\n",
      "Step 118: Loss = 724646.6858590499\n",
      "Step 120: Loss = 588487.8732186605\n",
      "Step 122: Loss = 562801.5801026076\n",
      "Step 124: Loss = 760099.2501023391\n",
      "Step 126: Loss = 479775.6811790924\n",
      "Step 128: Loss = 777016.4642477743\n",
      "Step 130: Loss = 412394.7068015055\n",
      "Step 132: Loss = 377202.4005644056\n",
      "Step 134: Loss = 344423.4897653151\n",
      "Step 136: Loss = 414906.66973850364\n",
      "Step 138: Loss = 413914.9267843254\n",
      "Step 140: Loss = 392623.3780086783\n",
      "Step 142: Loss = 234348.5209047203\n",
      "Step 144: Loss = 176399.78966590262\n",
      "Step 146: Loss = 153809.77611192735\n",
      "Step 148: Loss = 103764.74666849559\n",
      "Step 150: Loss = 72467.50055363588\n",
      "Step 152: Loss = 76911.21463903203\n",
      "Step 154: Loss = 49624.28056666802\n",
      "Step 156: Loss = 21384.350140834693\n",
      "Step 158: Loss = -54915.70986343641\n",
      "Step 160: Loss = -8039.216725220904\n",
      "Step 162: Loss = -121972.27502708626\n",
      "Step 164: Loss = -155046.06223040936\n",
      "Step 166: Loss = -185478.28197939612\n",
      "Step 168: Loss = -225499.4391870714\n",
      "Step 170: Loss = -226838.96061347786\n",
      "Step 172: Loss = -287707.89028122975\n",
      "Step 174: Loss = -298844.2538679503\n",
      "Step 176: Loss = -340924.96039557946\n",
      "Step 178: Loss = -335493.5212335333\n",
      "Step 180: Loss = -408910.54042174376\n",
      "Step 182: Loss = -434306.96922145155\n",
      "Step 184: Loss = -469157.40329219424\n",
      "Step 186: Loss = -492436.3535575238\n",
      "Step 188: Loss = -489359.48277131584\n",
      "Step 190: Loss = -535751.8153384961\n",
      "Step 192: Loss = -586951.1136335229\n",
      "Step 194: Loss = -606030.2387984378\n",
      "Step 196: Loss = -596670.91900222\n",
      "Step 198: Loss = -676661.572413074\n",
      "Step 200: Loss = -688461.5044396278\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m svi = SVI(model, guide, adam, loss=JitTrace_ELBO())\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     loss = \u001b[43msvi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamyloid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_lipid_droplet_area\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_factor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/svi.py:153\u001b[39m, in \u001b[36mSVI.step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m params = \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    148\u001b[39m     site[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m].unconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture.trace.nodes.values()\n\u001b[32m    149\u001b[39m )\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# zero gradients\u001b[39;00m\n\u001b[32m    156\u001b[39m pyro.infer.util.zero_grads(params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/optim/optim.py:155\u001b[39m, in \u001b[36mPyroOptim.__call__\u001b[39m\u001b[34m(self, params, *args, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_objs[p].optimizer.step(*args, **kwargs)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptim_objs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/torch/optim/adam.py:220\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[33;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[33;03m            and returns the loss.\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:428\u001b[39m, in \u001b[36mOptimizer._cuda_graph_capture_health_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    424\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m torch.compiler.is_compiling()\n\u001b[32m    425\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.backends.cuda.is_built()\n\u001b[32m    426\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available()\n\u001b[32m    427\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m         capturing = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    431\u001b[39m             group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups\n\u001b[32m    432\u001b[39m         ):\n\u001b[32m    433\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    434\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m                 + \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m    436\u001b[39m                 + \u001b[33m\"\u001b[39m\u001b[33m but param_groups\u001b[39m\u001b[33m'\u001b[39m\u001b[33m capturable is False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/torch/cuda/graphs.py:30\u001b[39m, in \u001b[36mis_current_stream_capturing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_current_stream_capturing\u001b[39m():\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": .01})\n",
    "svi = SVI(model, guide, adam, loss=JitTrace_ELBO())\n",
    "\n",
    "for step in range(1000):\n",
    "    loss = svi.step(amyloid.to(device), log_lipid_droplet_area.to(device), size_factor.to(device), counts.to(device))\n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step {step}: Loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cd59158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intercept_loc': tensor(0.8028, requires_grad=True),\n",
       " 'intercept_scale': tensor(0.4316, grad_fn=<AddBackward0>),\n",
       " 'amyloid_loc': tensor(0., requires_grad=True),\n",
       " 'amyloid_scale': tensor(7.4633, grad_fn=<AddBackward0>),\n",
       " 'u_loc': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 'u_scale_tril': tensor([[ 0.1334,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0118,  0.0807,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0089, -0.0052,  0.0932,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0090,  0.0038, -0.0037,  0.1098,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0086, -0.0050,  0.0051, -0.0056,  0.1247,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0063,  0.0040, -0.0054,  0.0067, -0.0081,  0.1391,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0072, -0.0047,  0.0059, -0.0086,  0.0074, -0.0063,  0.1567,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0070,  0.0058, -0.0046,  0.0080, -0.0109,  0.0086, -0.0120,  0.1616,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0038, -0.0025,  0.0027, -0.0052,  0.0109, -0.0205,  0.0376, -0.0777,\n",
       "           0.1566,  0.0000],\n",
       "         [-0.1187,  0.0751, -0.0856,  0.1141, -0.1089,  0.0630,  0.0048, -0.1965,\n",
       "           0.5947,  0.1497]], grad_fn=<AddBackward0>),\n",
       " 'r_loc': tensor(22.1635, grad_fn=<AddBackward0>),\n",
       " 'r_scale': tensor(3.4593, grad_fn=<AddBackward0>),\n",
       " 'amyloid': tensor(0.5913, requires_grad=True),\n",
       " 'Xu': Parameter containing:\n",
       " tensor([[0.0000],\n",
       "         [0.7778],\n",
       "         [1.5556],\n",
       "         [2.3333],\n",
       "         [3.1111],\n",
       "         [3.8889],\n",
       "         [4.6667],\n",
       "         [5.4444],\n",
       "         [6.2222],\n",
       "         [7.0000]], requires_grad=True),\n",
       " 'kernel.lengthscale': tensor(0.8706, grad_fn=<AddBackward0>),\n",
       " 'kernel.variance': tensor(1.1186, grad_fn=<AddBackward0>),\n",
       " 'r': tensor(0.6161, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(pyro.get_param_store())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aca6ce",
   "metadata": {},
   "source": [
    "# Sampling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23351d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "from torch.distributions import constraints\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def model(amyloid, log_lipid_droplet_area, size_factor, counts):\n",
    "    device = counts.device\n",
    "    N, K = counts.shape\n",
    "\n",
    "    # Intercept: one per feature\n",
    "    with pyro.plate(\"intercept_passes\", K):\n",
    "        intercept = pyro.sample(\"intercept\", dist.Normal(torch.zeros(1, device=device), 5.0))\n",
    "\n",
    "    # Amyloid effect: learnable weight per feature\n",
    "    amyloid_loc = pyro.param(\"amyloid\", torch.ones(K, device=device))\n",
    "\n",
    "    # Sparse GP\n",
    "    kernel = gp.kernels.RBF(\n",
    "        input_dim=1,\n",
    "        variance=log_lipid_droplet_area.var().to(device),\n",
    "        lengthscale=torch.tensor(0.05, device=device)\n",
    "    )\n",
    "    gpr = gp.models.VariationalSparseGP(\n",
    "        log_lipid_droplet_area.unsqueeze(-1),\n",
    "        Xu=torch.linspace(0, 7, 10, device=device).unsqueeze(-1),\n",
    "        y=None,\n",
    "        kernel=kernel,\n",
    "        likelihood=None\n",
    "    )\n",
    "    ld_loc, ld_scale = gpr(log_lipid_droplet_area.unsqueeze(-1))\n",
    "    with pyro.plate(\"ld_data\", N):\n",
    "        ld_sampled = pyro.sample(\"ld_sampled\", dist.Normal(ld_loc, ld_scale))  # shape [N]\n",
    "\n",
    "    # Expand: ld_sampled: [N] â†’ [N, K]\n",
    "    ld_effect = ld_sampled.unsqueeze(-1) * log_lipid_droplet_area.unsqueeze(-1)\n",
    "\n",
    "    # Logit: [N, K]\n",
    "    print(amyloid)\n",
    "    print(amyloid_loc)\n",
    "    logit = intercept + (amyloid.unsqueeze(-1) * amyloid_loc.unsqueeze(0)) + ld_effect + size_factor.unsqueeze(-1)\n",
    "    logit = torch.clamp(logit, -20.0, 20.0)\n",
    "\n",
    "    # Dispersion (can be shared or per-feature)\n",
    "    r = pyro.param(\"r\", torch.ones(K, device=device), constraint=constraints.positive)\n",
    "\n",
    "    with pyro.plate(\"feature\", K), pyro.plate(\"individual\", N):\n",
    "        pyro.sample(\"counts\", dist.NegativeBinomial(total_count=r, logits=logit), obs=counts)\n",
    "\n",
    "def guide(amyloid, log_lipid_droplet_area, size_factor, counts):\n",
    "    device = counts.device\n",
    "    N, K = counts.shape\n",
    "\n",
    "    # Intercept\n",
    "    intercept_loc = pyro.param(\"intercept_loc\", torch.zeros(K, device=device))\n",
    "    intercept_scale = pyro.param(\"intercept_scale\", torch.ones(K, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"intercept\", dist.Normal(intercept_loc, intercept_scale))\n",
    "\n",
    "    # Amyloid\n",
    "    amyloid_loc = pyro.param(\"amyloid_loc\", torch.zeros(K, device=device))\n",
    "    amyloid_scale = pyro.param(\"amyloid_scale\", torch.ones(K, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"amyloid\", dist.Normal(amyloid_loc, amyloid_scale))\n",
    "\n",
    "    # GP\n",
    "    kernel = gp.kernels.RBF(\n",
    "        input_dim=1,\n",
    "        variance=log_lipid_droplet_area.var().to(device),\n",
    "        lengthscale=torch.tensor(0.05, device=device)\n",
    "    )\n",
    "    gpr = gp.models.VariationalSparseGP(\n",
    "        log_lipid_droplet_area.unsqueeze(-1),\n",
    "        Xu=torch.linspace(0, 7, 10, device=device).unsqueeze(-1),\n",
    "        y=None,\n",
    "        kernel=kernel,\n",
    "        likelihood=None\n",
    "    )\n",
    "    gpr.guide()\n",
    "\n",
    "    # Dispersion (can also be sampled)\n",
    "    r_loc = pyro.param(\"r_loc\", torch.ones(K, device=device), constraint=constraints.positive)\n",
    "    r_scale = pyro.param(\"r_scale\", torch.ones(K, device=device), constraint=constraints.positive)\n",
    "    pyro.sample(\"r\", dist.LogNormal(r_loc, r_scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at site \"intercept\", invalid log_prob shape\n  Expected [], actual [366]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m all_counts = all_counts.to(device)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     loss = \u001b[43msvi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamyloid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_lipid_droplet_area\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     18\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/svi.py:145\u001b[39m, in \u001b[36mSVI.step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m poutine.trace(param_only=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m params = \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    148\u001b[39m     site[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m].unconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture.trace.nodes.values()\n\u001b[32m    149\u001b[39m )\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:250\u001b[39m, in \u001b[36mJitTrace_ELBO.loss_and_grads\u001b[39m\u001b[34m(self, model, guide, *args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_and_grads\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     loss, surrogate_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_surrogate_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     surrogate_loss.backward()\n\u001b[32m    254\u001b[39m     loss = loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:239\u001b[39m, in \u001b[36mJitTrace_ELBO.loss_and_surrogate_loss\u001b[39m\u001b[34m(self, model, guide, *args, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m loss, surrogate_loss\n\u001b[32m    237\u001b[39m     \u001b[38;5;28mself\u001b[39m._loss_and_surrogate_loss = loss_and_surrogate_loss\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loss_and_surrogate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/ops/jit.py:76\u001b[39m, in \u001b[36mCompiledFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m poutine.block():\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m poutine.trace(param_only=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m first_param_capture:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._param_names = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(first_param_capture.trace.nodes.keys()))\n\u001b[32m     79\u001b[39m unconstrained_params = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m     80\u001b[39m     pyro.param(name).unconstrained() \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param_names\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:193\u001b[39m, in \u001b[36mJitTrace_ELBO.loss_and_surrogate_loss.<locals>.loss_and_surrogate_loss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m loss = \u001b[32m0.0\u001b[39m\n\u001b[32m    192\u001b[39m surrogate_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43melbo_particle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43msurrogate_elbo_particle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/elbo.py:237\u001b[39m, in \u001b[36mELBO._get_traces\u001b[39m\u001b[34m(self, model, guide, args, kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_particles):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:57\u001b[39m, in \u001b[36mTrace_ELBO._get_trace\u001b[39m\u001b[34m(self, model, guide, args, kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[32m     53\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    against it.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     model_trace, guide_trace = \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[32m     61\u001b[39m         check_if_enumerated(guide_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/infer/enum.py:83\u001b[39m, in \u001b[36mget_importance_trace\u001b[39m\u001b[34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m guide_trace.nodes.values():\n\u001b[32m     82\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m             \u001b[43mcheck_site_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_trace, guide_trace\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/using_parameters_instead/.venv/lib/python3.13/site-packages/pyro/util.py:437\u001b[39m, in \u001b[36mcheck_site_shape\u001b[39m\u001b[34m(site, max_plate_nesting)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m actual_size, expected_size \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape), fillvalue=\u001b[32m1\u001b[39m\n\u001b[32m    435\u001b[39m ):\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m expected_size != -\u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m expected_size != actual_size:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    438\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    439\u001b[39m                 [\n\u001b[32m    440\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mat site \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, invalid log_prob shape\u001b[39m\u001b[33m'\u001b[39m.format(site[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    441\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, actual \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(expected_shape, actual_shape),\n\u001b[32m    442\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mTry one of the following fixes:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    443\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m- enclose the batched tensor in a with pyro.plate(...): context\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    444\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m- .to_event(...) the distribution being sampled\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    445\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m- .permute() data dimensions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    446\u001b[39m                 ]\n\u001b[32m    447\u001b[39m             )\n\u001b[32m    448\u001b[39m         )\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Check parallel dimensions on the left of max_plate_nesting.\u001b[39;00m\n\u001b[32m    451\u001b[39m enum_dim = site[\u001b[33m\"\u001b[39m\u001b[33minfer\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33m_enumerate_dim\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: at site \"intercept\", invalid log_prob shape\n  Expected [], actual [366]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"
     ]
    }
   ],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": .01})\n",
    "svi = SVI(model, guide, adam, loss=JitTrace_ELBO())\n",
    "\n",
    "amyloid = amyloid.to(device)\n",
    "log_lipid_droplet_area = log_lipid_droplet_area.to(device)size_factor.to(device), all_counts.to(device)\n",
    "\n",
    "for step in range(100):\n",
    "    loss = svi.step()\n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step {step}: Loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3dc8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
